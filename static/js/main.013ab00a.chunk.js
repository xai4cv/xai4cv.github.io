(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{66:function(e){e.exports={a:[{img_url:"assets/images/filip_radenovic.jpeg",name:"Filip Radenovic",organization:"Meta AI",website:"https://filipradenovic.github.io"},{img_url:"assets/images/abhishek_kadian.jpg",name:"Abhishek Kadian",organization:"Meta AI",website:"https://abhiskk.github.io"},{img_url:"assets/images/deepti_ghadiyaram.png",name:"Deepti Ghadiyaram",organization:"Meta AI",website:"https://deeptigp.github.io"},{img_url:"assets/images/dhruv_mahajan.jpeg",name:"Dhruv Mahajan",organization:"Meta AI",website:"https://ai.facebook.com/people/dhruv-mahajan"},{img_url:"assets/images/devi_parikh.jpeg",name:"Devi Parikh",organization:"Meta AI",website:"https://faculty.cc.gatech.edu/~parikh"},{img_url:"assets/images/vignesh_ramanathan.jpeg",name:"Vignesh Ramanathan",organization:"Meta AI",website:"https://ai.facebook.com/people/vignesh-ramanathan"},{img_url:"assets/images/jun_xie.jpeg",name:"Jun Xie",organization:"Meta AI",website:"https://www.linkedin.com/in/junxie19"}]}},67:function(e){e.exports={a:[{img_url:"assets/images/antonio_torralba.jpeg",name:"Antonio Torralba",organization:"MIT",website:"http://web.mit.edu/torralba/www"},{img_url:"assets/images/yixin_wang.jpeg",name:"Yixin Wang",organization:"University of Michigan",website:"https://yixinwang.github.io"},{img_url:"assets/images/rich_caruana.jpeg",name:"Rich Caruana",organization:"MSR",website:"https://www.microsoft.com/en-us/research/people/rcaruana"},{img_url:"assets/images/hima_lakkaraju.jpeg",name:"Hima Lakkaraju",organization:"Harvard University",website:"https://himalakkaraju.github.io"},{img_url:"assets/images/trevor_darrell.jpeg",name:"Trevor Darrell",organization:"UC Berkeley",website:"https://people.eecs.berkeley.edu/~trevor"},{img_url:"assets/images/pradeep_ravikumar.jpeg",name:"Pradeep Ravikumar",organization:"Carnegie Mellon University",website:"https://www.cs.cmu.edu/~pradeepr"},{img_url:"assets/images/serena_yeung.jpeg",name:"Serena Yeung",organization:"Stanford",website:"https://ai.stanford.edu/~syyeung"},{img_url:"assets/images/been_kim.jpeg",name:"Been Kim",organization:"Google Brain",website:"https://beenkim.github.io"}]}},78:function(e,a,t){e.exports=t(97)},83:function(e,a,t){},84:function(e,a,t){},85:function(e,a,t){},97:function(e,a,t){"use strict";t.r(a);var n,l,i=t(0),r=t.n(i),s=t(6),c=t.n(s),o=(t(83),t(18)),m=t(19),u=t(22),d=t(21),g=(t(84),t(135)),E=t(53),b=t(10),p=t(69),h=Object(p.a)({palette:{primary:{light:"#9ccc65",main:"#3b4252",dark:"#33691e",contrastText:"#fff"},secondary:{light:"#ff7961",main:"#f44336",dark:"#ba000d",contrastText:"#000"}},typography:{useNextVariants:!0}}),f=t(28),v=t(131),y=t(132),N=t(130),x=t(138),I=t(136),k=t(137),M=t(133),A=(t(85),t(86),t(65)),S=t.n(A),w=t(128),j=t(5),C=t(129),D={root:{width:"100%",flexGrow:1},buttonLink:{color:h.palette.primary.contrastText,textDecoration:"none"},buttonsSide:{textAlign:"right"},sectionDesktop:(n={display:"none"},Object(f.a)(n,h.breakpoints.up("md"),{display:"flex"}),Object(f.a)(n,"flex",1),Object(f.a)(n,"flexDirection","row-reverse"),n),sectionMobile:(l={display:"flex"},Object(f.a)(l,h.breakpoints.up("md"),{display:"none"}),Object(f.a)(l,"flex",1),Object(f.a)(l,"flexDirection","row-reverse"),l)},H=function(e){Object(u.a)(t,e);var a=Object(d.a)(t);function t(){var e;Object(o.a)(this,t);for(var n=arguments.length,l=new Array(n),i=0;i<n;i++)l[i]=arguments[i];return(e=a.call.apply(a,[this].concat(l))).state={mobileMoreAnchorEl:null,dialogOpen:!1},e.handleMobileMenuOpen=function(a){e.setState({mobileMoreAnchorEl:a.currentTarget})},e.handleMobileMenuClose=function(){e.setState({mobileMoreAnchorEl:null})},e}return Object(m.a)(t,[{key:"render",value:function(){var e=this.props.classes,a=this.state.mobileMoreAnchorEl,t=Boolean(a),n=r.a.createElement(I.a,{anchorEl:a,anchorOrigin:{vertical:"top",horizontal:"right"},transformOrigin:{vertical:"top",horizontal:"right"},open:t,onClose:this.handleMobileMenuClose},r.a.createElement(w.a,{onClickAway:this.handleMobileMenuClose},r.a.createElement(k.a,null,r.a.createElement(x.a,{onClick:this.handleMobileMenuClose},r.a.createElement(C.a,{underline:"none",className:[e.buttonLink,e.buttonsSide].join(" "),href:"mailto:filipradenovic@fb.com"},r.a.createElement(N.a,{disableRipple:!0,disableFocusRipple:!0,color:"default"},r.a.createElement("i",{className:"fa fa-envelope fa-lg"})))))));return r.a.createElement("div",{className:e.root},r.a.createElement(v.a,{position:"static",color:"primary"},r.a.createElement(y.a,null,r.a.createElement(C.a,{underline:"none",align:"left",className:[e.buttonLink,e.grow].join(" "),href:"./workshop"},r.a.createElement("b",null,"XAI4CV")),r.a.createElement("div",{className:e.sectionDesktop},r.a.createElement(C.a,{underline:"none",className:[e.buttonLink,e.buttonsSide].join(" "),href:"mailto:filipradenovic@fb.com  "},r.a.createElement(N.a,{disableRipple:!0,disableFocusRipple:!0,color:"inherit"},r.a.createElement("i",{className:"fa fa-envelope fa-lg"})))),r.a.createElement("div",{className:e.sectionMobile},r.a.createElement(M.a,{"aria-haspopup":"true",onClick:this.handleMobileMenuOpen,color:"inherit"},r.a.createElement(S.a,null))),n)))}}]),t}(r.a.Component),P=Object(j.a)(D)(H),T=t(101),O=t(134),V=function(e){Object(u.a)(t,e);var a=Object(d.a)(t);function t(){var e;Object(o.a)(this,t);for(var n=arguments.length,l=new Array(n),i=0;i<n;i++)l[i]=arguments[i];return(e=a.call.apply(a,[this].concat(l))).state={checked:!1},e}return Object(m.a)(t,[{key:"render",value:function(){var e=this.props.classes;return r.a.createElement("div",{className:e.root},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:10,md:9,lg:9,className:e.content},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:12,lg:12},r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h4",gutterBottom:!0,align:"left"},"Explainable Artificial Intelligence for Computer Vision (XAI4CV)"),r.a.createElement(T.a,{className:e.SectionHeader,variant:"h6",gutterBottom:!0,align:"left"},"Meta AI"))),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Workshops")),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:9,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement(C.a,{href:"./workshop"},r.a.createElement("b",null,"XAI4CV at CVPR 2022"))))),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Contact")),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:9,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},"Email: ",r.a.createElement(C.a,{href:"mailto:filipradenovic@fb.com"},"filipradenovic@fb.com"))))))))))}}]),t}(r.a.Component),R=Object(j.a)(function(e){return{content:{margin:"0 auto",marginTop:"1.5em"},root:{},gridItem:{padding:e.spacing(1.5)},sectionHeader:{marginTop:"0.15em"},container:{padding:e.spacing(2)},footer:{marginTop:"0.15em",fontSize:14}}})(V),L=t(66),B=t(139),z=Object(j.a)(function(e){return{avatar:{width:100,height:100,margin:"0 auto"},gridItem:{padding:e.spacing(2)}}})(function(e){var a=[],t=3;a=e.people?e.people:L.a,e.lgSize&&(t=e.lgSize);var n=a.map(function(a){var n=Math.random();return r.a.createElement(O.a,{item:!0,key:n,xs:12,sm:8,md:6,lg:t},r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:a.website},r.a.createElement(B.a,{className:e.classes.avatar,src:a.img_url})),r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:a.website},r.a.createElement(T.a,{variant:"subtitle1"},r.a.createElement("b",null,a.name))),r.a.createElement(T.a,{variant:"caption"},a.organization))});return r.a.createElement(O.a,{container:!0,direction:"row",justify:"center",alignItems:"flex-start"},n)}),_=t(67),K=Object(j.a)(function(e){return{avatar:{width:100,height:100,margin:"0 auto"},gridItem:{padding:e.spacing(2)}}})(function(e){var a=[],t=3;a=e.speakers?e.speakers:_.a,e.lgSize&&(t=e.lgSize);var n=a.map(function(a){var n=Math.random();return r.a.createElement(O.a,{item:!0,key:n,xs:12,sm:8,md:6,lg:t},r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:a.website},r.a.createElement(B.a,{className:e.classes.avatar,src:a.img_url})),r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:a.website},r.a.createElement(T.a,{variant:"subtitle1"},r.a.createElement("b",null,a.name))),r.a.createElement(T.a,{variant:"caption"},a.organization))});return r.a.createElement(O.a,{container:!0,direction:"row",justify:"center",alignItems:"flex-start"},n)}),W=function(e){Object(u.a)(t,e);var a=Object(d.a)(t);function t(){var e;Object(o.a)(this,t);for(var n=arguments.length,l=new Array(n),i=0;i<n;i++)l[i]=arguments[i];return(e=a.call.apply(a,[this].concat(l))).state={checked:!1},e}return Object(m.a)(t,[{key:"render",value:function(){var e=this.props.classes;return document.title="Workshop",r.a.createElement("div",{className:e.root},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:10,md:9,lg:9,className:e.content},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:12,lg:12},r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,md:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h4",gutterBottom:!0,align:"center"},"XAI4CV: Explainable Artificial Intelligence for Computer Vision")),r.a.createElement(O.a,{item:!0,xs:12,md:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",gutterBottom:!0,align:"center"},"Workshop at CVPR 2022")),r.a.createElement("div",{className:e.container}),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Date:")," Monday, June 20, 2022 ",r.a.createElement("br",null),r.a.createElement("b",null,"Venue:")," New Orleans, Louisiana",r.a.createElement("br",null),r.a.createElement("br",null),r.a.createElement("b",null,"Motivation:")," Provide a common forum for both computer vision practitioners in the industry and academia to initiate discussions and propose best ways to build explainable models that can benefit the global community.")),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Abstract")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},"Computer vision (CV) models are often used to improve applications and products and are very successful. However, these models are usually black-box in nature and do not provide explanations for their predictions, which sometimes leads to confusing behaviour. The current lack of transparency in CV models is one of the biggest barriers in building trust among consumers, often resulting in severe backlash when models make embarrassing mistakes. Trust in the models can be improved by making them fair, easily understandable for everyone, and correctable if necessary. The need for trustworthiness has prompted recent clauses in GDPR regulations that require models to also explain their results in a way a naive consumer can understand.",r.a.createElement("br",null),r.a.createElement("br",null),'With socio-political implications of AI in mind, this workshop aims to motivate proactive adaptation of explainability in computer vision systems. Specifically, our aim is to spark healthy conversations that address building top-performing explainable computer vision systems that not only identify "what" and "where" different visual entities occur in an image, but also provide a human-like reasoning of "why" the model made those predictions. Furthermore, such systems should allow a user to provide feedback and thereby correct potentially harmful mispredictions with minimal effort.')),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left",id:"call_for_papers"},"Call for Papers")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},"We welcome 2 page (including references) extended abstract submissions that showcase successful application of XAI methods on popular computer vision tasks, helping users better understand the results of a model. Moreover, we also welcome the submission of novel XAI for CV techniques, visualizations, and practical libraries.",r.a.createElement("br",null)," ",r.a.createElement("br",null),"Finally, we encourage submitting papers accepted in the CVPR 2022 main program, or in a relevant 2022 conference, in which case authors do not need to prepare extended abstract, but simply submit the camera-ready version of the accepted paper.",r.a.createElement("br",null)," ",r.a.createElement("br",null),"Note that, accepted extended abstracts will not be published in conjunction with the CVPR 2022 proceedings.")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Timeline")),r.a.createElement("br",null),r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},"CMT portal opens on ",r.a.createElement("b",null,"Feb 2, 2022"),". ",r.a.createElement("br",null),"Submissions until ",r.a.createElement("b",null,"May 18, 2022"),". ",r.a.createElement("br",null),"Rolling acceptances from ",r.a.createElement("b",null,"May 1, 2022")," until ",r.a.createElement("b",null,"May 20, 2022"),". ",r.a.createElement("br",null),"Spotlight / Poster decisions on ",r.a.createElement("b",null,"May 23, 2022"),".")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Submission instructions")),r.a.createElement("br",null),r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"Extended Abstracts: ")," All submissions should be in the anonymized CVPR 2022 format, and submissions will be subjected to the double-blind review process. Submitted extended abstracts will be reviewed by 1-2 reviewers, with the organizing team serving as a program committee.",r.a.createElement("br",null),r.a.createElement("br",null),r.a.createElement("b",null,"Papers accepted in a relevant 2022 conference: ")," Authors of papers accepted in the CVPR 2022 main program, or in a relevant 2022 conference, are encouraged to submit the camera-ready version and present their work at our workshop. Organizing team will review the relevance of submitted papers to the XAI4CV workshop.",r.a.createElement("br",null),r.a.createElement("br",null),r.a.createElement("b",null,"Submissions")," can be done at ",r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:"https://cmt3.research.microsoft.com/XAI4CV2022"},r.a.createElement("b",null,"https://cmt3.research.microsoft.com/XAI4CV2022")),".")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Attendance")),r.a.createElement("br",null),r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"Posters: ")," All accepted submissions will be invited to participate in an ",r.a.createElement("b",null,"in-person")," poster session at our workshop. Additionally, the authors will be asked to upload their posters which will be hosted on our webpage.",r.a.createElement("br",null),r.a.createElement("br",null),r.a.createElement("b",null,"Spotlights: ")," We will pick the best 6 papers from among the submissions / main conference to be presented as spotlights. Presentations can either be ",r.a.createElement("b",null,"in-person")," or ",r.a.createElement("b",null,"pre-recorded"),".",r.a.createElement("br",null),r.a.createElement("br",null),"Abiding by the ",r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:"https://cvpr2022.thecvf.com/registration"},r.a.createElement("b",null,"CVPR guidelines")),", all accepted papers ",r.a.createElement("b",null,"must be presented by one of the authors"),".")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Topics")),r.a.createElement(T.a,{className:e.sectionHeader,variant:"body2",align:"left"},r.a.createElement("ul",null,r.a.createElement("li",null," Building inherently interpretable CV models,"),r.a.createElement("li",null," Black-box CV model explanations visualized on test images and / or presented in a human interpretable language,"),r.a.createElement("li",null," Object classification / detection / segmentation model explanations,"),r.a.createElement("li",null," Action detection model explanations,"),r.a.createElement("li",null," VQA model explanations,"),r.a.createElement("li",null," Medical imaging model explanations,"),r.a.createElement("li",null," Human intervention and correctability in computer vision,"),r.a.createElement("li",null," Machine teaching via explanations,"),r.a.createElement("li",null," Constructing datasets for benchmarking explainability,"),r.a.createElement("li",null," Offline and online evaluation methods for explanations,"),r.a.createElement("li",null," Building practical libraries for explainable computer vision, and their integration with popular CV libraries.")))),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Invited Speakers")),r.a.createElement(K,null),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Schedule")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"body1",align:"left"},"Detailed schedule available at ",r.a.createElement(C.a,{target:"_blank",rel:"noopener",href:"./workshop-schedule"},r.a.createElement("b",null,"xai4cv.github.io/workshop-schedule")),".")),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"09:00 AM - 09:10 AM: ")," Opening Remarks"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"09:10 AM - 09:50 AM: ")," Spotlight Session 1"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"09:50 AM - 10:30 AM: ")," Coffee Break + Poster Session 1"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"10:30 AM - 11:00 AM: ")," Invited Talk - Antonio Torralba"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"11:00 AM - 11:30 AM: ")," Invited Talk - Yixin Wang"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"11:30 AM - 12:00 AM: ")," Invited Talk - Rich Caruana"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"12:00 AM - 12:50 PM: ")," Lunch Break"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"12:50 PM - 01:30 PM: ")," Spotlight Session 2"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"01:30 PM - 02:00 PM: ")," Invited Talk - Hima Lakkaraju"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"02:00 PM - 02:30 PM: ")," Invited Talk - Trevor Darrell"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"02:30 PM - 03:10 PM: ")," Coffee Break + Poster Session 2"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"03:10 PM - 03:40 PM: ")," Invited Talk - Pradeep Ravikumar"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"03:40 PM - 04:10 PM: ")," Invited Talk - Serena Yeung"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"04:10 PM - 04:40 PM: ")," Invited Talk - Been Kim"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"04:40 PM - 04:50 PM: ")," Break"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"04:50 PM - 05:50 PM: ")," Panel Discussion"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("b",null,"05:50 PM - 06:00 PM: ")," Closing Remarks"))),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Organizers")),r.a.createElement(z,null),r.a.createElement("div",{className:e.container})))))))}}]),t}(r.a.Component),X=Object(j.a)(function(e){return{content:{margin:"0 auto",marginTop:"1.5em"},root:{},gridItem:{padding:e.spacing(1.5)},sectionHeader:{marginTop:"0.15em"},container:{padding:e.spacing(2)},footer:{marginTop:"0.15em",fontSize:14},people:{margin:"0 auto",marginTop:"1.5em"}}})(W),F=function(e){Object(u.a)(t,e);var a=Object(d.a)(t);function t(){var e;Object(o.a)(this,t);for(var n=arguments.length,l=new Array(n),i=0;i<n;i++)l[i]=arguments[i];return(e=a.call.apply(a,[this].concat(l))).state={checked:!1},e}return Object(m.a)(t,[{key:"render",value:function(){var e=this.props.classes;return document.title="WorkshopSchedule",r.a.createElement("div",{className:e.root},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:10,md:9,lg:9,className:e.content},r.a.createElement(O.a,{container:!0,justify:"center",alignContent:"center"},r.a.createElement(O.a,{item:!0,xs:12,lg:12},r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,md:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h4",gutterBottom:!0,align:"center"},"XAI4CV: Explainable Artificial Intelligence for Computer Vision")),r.a.createElement(O.a,{item:!0,xs:12,md:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",gutterBottom:!0,align:"center"},"Workshop at CVPR 2022")),r.a.createElement("div",{className:e.container}),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"h5",align:"left"},"Detailed Schedule")),r.a.createElement(O.a,{item:!0,xs:12,className:e.gridItem},r.a.createElement(T.a,{className:e.sectionHeader,variant:"subtitle1",align:"left"},r.a.createElement("b",null,"Date:")," Monday, June 20, 2022 ",r.a.createElement("br",null),r.a.createElement("b",null,"Venue:")," New Orleans, Louisiana ",r.a.createElement("br",null))),r.a.createElement("div",{className:e.container}),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"09:00 AM - 09:10 AM: ")," Opening Remarks"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"09:10 AM - 09:50 AM: ")," Spotlight Session 1 (",r.a.createElement("i",null,"8 min + 2 min QA"),")"),r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("ul",null,r.a.createElement("li",null,"ID 06: ",r.a.createElement("b",null,"HIVE: Evaluating the Human Interpretability of Visual Explanations.")," Sunnie S. Y. Kim, Nicole Meister, Vikram V. Ramaswamy, Ruth C Fong, Olga Russakovsky."),r.a.createElement("li",null,"ID 11: ",r.a.createElement("b",null,"Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention.")," Yu Yang, Seungbae Kim, Jungseock Joo."),r.a.createElement("li",null,"ID 17: ",r.a.createElement("b",null,"Causality for Inherently Explainable Transformers: CAT-XPLAIN.")," Subash Khanal, Benjamin Brodie, Xin Xing, Ai-Ling Lin, Nathan Jacobs."),r.a.createElement("li",null,"ID 20: ",r.a.createElement("b",null,"Do learned representations respect causal relationships?")," Lan Wang, Vishnu Boddeti."))))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"09:50 AM - 10:30 AM: ")," Coffee Break + Poster Session 1"),r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("ul",null,r.a.createElement("li",null,"ID 02: ",r.a.createElement("b",null,"Finding and Fixing Spurious Patterns with Explanations.")," Gregory Plump, Marco Tulio Ribeiro, Ameet Talwalkar."),r.a.createElement("li",null,"ID 03: ",r.a.createElement("b",null,"Sanity Simulations for Saliency Methods.")," Joon Sik Kim, Gregory Plumb, Ameet Talwalkar."),r.a.createElement("li",null,"ID 04: ",r.a.createElement("b",null,"Xplique: A Deep Learning Explainability Toolbox.")," Thomas FEL, Lucas Hervier, David Vigouroux, Antonin Poche, Justin Plakoo, Remi Cadene, Mathieu Chalvidal, Julien Colin, Thibaut Boissin, Louis B\xe9thune, Agustin Picard, Claire NICODEME, Laurent Gardes, Gr\xe9gory Flandin, Thomas Serre."),r.a.createElement("li",null,"ID 06: ",r.a.createElement("b",null,"HIVE: Evaluating the Human Interpretability of Visual Explanations.")," Sunnie S. Y. Kim, Nicole Meister, Vikram V. Ramaswamy, Ruth C Fong, Olga Russakovsky."),r.a.createElement("li",null,"ID 10: ",r.a.createElement("b",null,"Give Users What They Want: Labeled Arrows.")," Severine Soltani, Michael Pazzani."),r.a.createElement("li",null,"ID 11: ",r.a.createElement("b",null,"Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention.")," Yu Yang, Seungbae Kim, Jungseock Joo."),r.a.createElement("li",null,"ID 12: ",r.a.createElement("b",null,"HINT: Hierarchical Neuron Concept Explainer.")," Andong Wang, W.N. Lee, Xiaojuan Qi"),r.a.createElement("li",null,"ID 17: ",r.a.createElement("b",null,"Causality for Inherently Explainable Transformers: CAT-XPLAIN.")," Subash Khanal, Benjamin Brodie, Xin Xing, Ai-Ling Lin, Nathan Jacobs."),r.a.createElement("li",null,"ID 18: ",r.a.createElement("b",null,"Ensembles for Improved Explanation of Image Classification.")," Aadil Ahamed, Kamran Alipour, Michael Pazzani, Sateesh Kumar."),r.a.createElement("li",null,"ID 20: ",r.a.createElement("b",null,"Do learned representations respect causal relationships?")," Lan Wang, Vishnu Boddeti."),r.a.createElement("li",null,"ID 21: ",r.a.createElement("b",null,"ELUDE: Generating Interpretable Explanations via a Decomposition into Labelled and Unlabelled features.")," Vikram V. Ramaswamy, Sunnie S. Y. Kim, Nicole Meister, Ruth C Fong, Olga Russakovsky."),r.a.createElement("li",null,"ID 22: ",r.a.createElement("b",null,"Explaining Local Discrepancies between Image Classification Models.")," Thibault Laugel, Xavier Renard, Marcin Detyniecki."),r.a.createElement("li",null,"ID 23: ",r.a.createElement("b",null,"CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations.")," Leonard Salewski, A. Sophia Koepke, Hendrik P. A. Lensch, Zeynep Akata."),r.a.createElement("li",null,"ID 24: ",r.a.createElement("b",null,"Cycle-Consistent Counterfactuals by Latent Transformations.")," Saeed Khorram, Li Fuxin."),r.a.createElement("li",null,"ID 26: ",r.a.createElement("b",null,"Subspace Based Visualization for Embedding Network.")," Xiaotong Liu, Abby Stylianou, Zeyu Zhang, Robert Pless."))))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"10:30 AM - 11:00 AM: ")," Invited Talk - Antonio Torralba"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"11:00 AM - 11:30 AM: ")," Invited Talk - Yixin Wang"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"11:30 AM - 12:00 AM: ")," Invited Talk - Rich Caruana"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"12:00 AM - 12:50 PM: ")," Lunch Break"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"12:50 PM - 01:30 PM: ")," Spotlight Session 2 (",r.a.createElement("i",null,"8 min + 2 min QA"),")"),r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("ul",null,r.a.createElement("li",null,"ID 27: ",r.a.createElement("b",null,"A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information.")," Matthew Kowal, Mennatullah Siam, Md Amirul Islam, Neil Bruce, Rick Wildes, Konstantinos G Derpanis."),r.a.createElement("li",null,"ID 31: ",r.a.createElement("b",null,"Consistent Explanations by Contrastive Learning.")," Vipin Pillai, Soroush Abbasi Koohpayegani, Ashley Ouligian, Dennis Fong, Hamed Pirsiavash."),r.a.createElement("li",null,"ID 35: ",r.a.createElement("b",null,"OccAM's Laser: Occlusion-based Attribution Maps for 3D Object Detectors on LiDAR Data.")," David Schinagl, Georg Krispel, Horst Possegger, Peter M. Roth, Horst Bischof."),r.a.createElement("li",null,"ID 54: ",r.a.createElement("b",null,"B-cos Networks: Alignment is All We Need for Interpretability.")," Moritz B\xf6hle, Mario Fritz, Bernt Schiele."))))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"01:30 PM - 02:00 PM: ")," Invited Talk - Hima Lakkaraju"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"02:00 PM - 02:30 PM: ")," Invited Talk - Trevor Darrell"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"02:30 PM - 03:10 PM: ")," Coffee Break + Poster Session 2"),r.a.createElement(T.a,{className:e.SectionHeader,variant:"body2",align:"left"},r.a.createElement("ul",null,r.a.createElement("li",null,"ID 27: ",r.a.createElement("b",null,"A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information.")," Matthew Kowal, Mennatullah Siam, Md Amirul Islam, Neil Bruce, Rick Wildes, Konstantinos G Derpanis."),r.a.createElement("li",null,"ID 31: ",r.a.createElement("b",null,"Consistent Explanations by Contrastive Learning.")," Vipin Pillai, Soroush Abbasi Koohpayegani, Ashley Ouligian, Dennis Fong, Hamed Pirsiavash."),r.a.createElement("li",null,"ID 32: ",r.a.createElement("b",null,"Testing Explanation Algorithms on Transformers.")," Mingqi Jiang, Saeed Khorram, Li Fuxin."),r.a.createElement("li",null,"ID 33: ",r.a.createElement("b",null,"FD-CAM: Improving Faithfulness and Discriminability of Visual Explanation for CNNs.")," Hui Li, Zihao Li, Rui Ma, Tieru Wu."),r.a.createElement("li",null,"ID 34: ",r.a.createElement("b",null,"Exploring Concept Contribution Spatially: Hidden Layer Interpretation with Spatial Activation Concept Vector.")," Andong Wang, W.N. Lee."),r.a.createElement("li",null,"ID 35: ",r.a.createElement("b",null,"OccAM's Laser: Occlusion-based Attribution Maps for 3D Object Detectors on LiDAR Data.")," David Schinagl, Georg Krispel, Horst Possegger, Peter M. Roth, Horst Bischof."),r.a.createElement("li",null,"ID 36: ",r.a.createElement("b",null,"Pose Tutor: An Explainable System for Correction in the Wild.")," Bhat Dittakavi, Bharathi Callepalli, Sai Vikas Desai, Divyagna Bavikadi, Soumi Chakraborty, Nishant S Reddy, Ayon Sharma, Vineeth N Balasubramanian."),r.a.createElement("li",null,"ID 39: ",r.a.createElement("b",null,"CheXplaining in Style: Counterfactual Explanations for Chest X-rays.")," Matan Atad, Vitalii Dmytrenko, Yitong Li, Xinyue Zhang, Matthias Keicher, Ashkan Khakzar, Nassir Navab."),r.a.createElement("li",null,"ID 42: ",r.a.createElement("b",null,"Auditing Privacy Protection in Split Computing via Data-Free Model Inversion.")," Xin Dong, Hongxu Yin, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov."),r.a.createElement("li",null,"ID 44: ",r.a.createElement("b",null,"Towards ML Methods for Biodiversity: A Novel Wild Bee Dataset and Evaluations of XAI Methods for ML-Assisted Rare Species Annotations")," Teodor Chiaburu."),r.a.createElement("li",null,"ID 46: ",r.a.createElement("b",null,"Spatial-temporal Concept based Explanation of 3D ConvNets.")," Ying Ji, Yu Wang, Kensaku Mori, Jien Kato."),r.a.createElement("li",null,"ID 49: ",r.a.createElement("b",null,"Visual correspondence-based explanations improve human-AI team accuracy.")," Anh Nguyen, GIANG NGUYEN, Mohammad Reza Taesiri."),r.a.createElement("li",null,"ID 50: ",r.a.createElement("b",null,"Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations.")," Ziyan Yang, Kushal Kafle, Franck Dernoncourt, Vicente Ordonez."),r.a.createElement("li",null,"ID 52: ",r.a.createElement("b",null,"Gradient-weighted Class Activation Mapping for spatio temporal graph convolutional network.")," PRATYUSHA DAS, ANTONIO ORTEGA."),r.a.createElement("li",null,"ID 54: ",r.a.createElement("b",null,"B-cos Networks: Alignment is All We Need for Interpretability.")," Moritz B\xf6hle, Mario Fritz, Bernt Schiele."))))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"03:10 PM - 03:40 PM: ")," Invited Talk - Pradeep Ravikumar"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"03:40 PM - 04:10 PM: ")," Invited Talk - Serena Yeung"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"04:10 PM - 04:40 PM: ")," Invited Talk - Been Kim"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"04:40 PM - 04:50 PM: ")," Break"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"04:50 PM - 05:50 PM: ")," Panel Discussion"))),r.a.createElement(O.a,{container:!0,justify:"flex-start"},r.a.createElement(O.a,{item:!0,xs:12,lg:12,className:e.gridItem},r.a.createElement(T.a,{className:e.SectionHeader,variant:"body1",align:"left"},r.a.createElement("b",null,"05:50 PM - 06:00 PM: ")," Closing Remarks"))),r.a.createElement("div",{className:e.container})))))))}}]),t}(r.a.Component),G=Object(j.a)(function(e){return{content:{margin:"0 auto",marginTop:"1.5em"},root:{},gridItem:{padding:e.spacing(1.5)},sectionHeader:{marginTop:"0.15em"},container:{padding:e.spacing(2)},footer:{marginTop:"0.15em",fontSize:14},people:{margin:"0 auto",marginTop:"1.5em"}}})(F),Y=function(e){Object(u.a)(t,e);var a=Object(d.a)(t);function t(){return Object(o.a)(this,t),a.apply(this,arguments)}return Object(m.a)(t,[{key:"render",value:function(){return r.a.createElement(g.a,{theme:h},r.a.createElement(E.a,{basename:"/"},r.a.createElement("div",{className:"App"},r.a.createElement("header",{className:"App-header"},r.a.createElement(P,null)),r.a.createElement("div",null,r.a.createElement(b.a,{path:"/",exact:!0,component:R}),r.a.createElement(b.a,{path:"/workshop",component:X}),r.a.createElement(b.a,{path:"/workshop-schedule",component:G})))))}}]),t}(r.a.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));c.a.render(r.a.createElement(Y,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(e){e.unregister()})}},[[78,1,2]]]);
//# sourceMappingURL=main.013ab00a.chunk.js.map